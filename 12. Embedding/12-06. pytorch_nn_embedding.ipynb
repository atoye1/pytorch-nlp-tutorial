{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 임베딩 층은 룩업 테이블이다."
      ],
      "metadata": {
        "id": "g-M6Qi1VjRY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S-D0d-X3jA7H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
        "word_set = set(train_data.split())\n",
        "\n",
        "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
        "vocab = {word: i+2 for i, word in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j4PHvj3jGqi",
        "outputId": "ce110440-e31a-4470-8738-02adba09bbfb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'to': 2, 'know': 3, 'how': 4, 'need': 5, 'code': 6, 'you': 7, '<unk>': 0, '<pad>': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 집합의 크기만큼의 행을 가지는 테이블 생성.\n",
        "embedding_table = torch.FloatTensor([\n",
        "                               [ 0.0,  0.0,  0.0],\n",
        "                               [ 0.0,  0.0,  0.0],\n",
        "                               [ 0.2,  0.9,  0.3],\n",
        "                               [ 0.1,  0.5,  0.7],\n",
        "                               [ 0.2,  0.1,  0.8],\n",
        "                               [ 0.4,  0.1,  0.1],\n",
        "                               [ 0.1,  0.8,  0.9],\n",
        "                               [ 0.6,  0.1,  0.1]])"
      ],
      "metadata": {
        "id": "MoxV6Xo0jH3p"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = 'you need to run'.split()\n",
        "idxes = []\n",
        "\n",
        "# 각 단어를 정수로 변환\n",
        "for word in sample:\n",
        "  try:\n",
        "    idxes.append(vocab[word])\n",
        "  # 단어 집합에 없는 단어일 경우 <unk>로 대체된다.\n",
        "  except KeyError:\n",
        "    idxes.append(vocab['<unk>'])\n",
        "idxes = torch.LongTensor(idxes)\n",
        "\n",
        "# 각 정수를 인덱스로 임베딩 테이블에서 값을 가져온다.\n",
        "lookup_result = embedding_table[idxes, :]\n",
        "print(lookup_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKL9-0X2jJI5",
        "outputId": "f791d880-4943-4c38-9094-3670b23e164d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6000, 0.1000, 0.1000],\n",
            "        [0.4000, 0.1000, 0.1000],\n",
            "        [0.2000, 0.9000, 0.3000],\n",
            "        [0.0000, 0.0000, 0.0000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 임베딩 층 사용하기"
      ],
      "metadata": {
        "id": "L8zK8DapjbeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
        "word_set = set(train_data.split())\n",
        "\n",
        "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
        "vocab = {tkn: i+2 for i, tkn in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1"
      ],
      "metadata": {
        "id": "hnUprmtCjKLR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n",
        "                               embedding_dim=3,\n",
        "                               padding_idx=1)"
      ],
      "metadata": {
        "id": "g4Jl0XfejMHB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjVsgSJkjNIg",
        "outputId": "9eb59fdb-c710-4127-c227-d130d51302b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.1554, -0.6474,  0.0574],\n",
            "        [ 0.0000,  0.0000,  0.0000],\n",
            "        [ 1.0383, -1.8434, -0.5678],\n",
            "        [ 0.4212, -0.5064,  2.0984],\n",
            "        [ 0.4647,  0.0217,  1.3079],\n",
            "        [-0.3444,  1.3380, -0.1798],\n",
            "        [ 1.4049,  0.5206, -1.3689],\n",
            "        [-0.6686,  1.2110,  0.9282]], requires_grad=True)\n"
          ]
        }
      ]
    }
  ]
}