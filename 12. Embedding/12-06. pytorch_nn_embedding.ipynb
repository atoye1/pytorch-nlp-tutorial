{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-M6Qi1VjRY8"
      },
      "source": [
        "## 1. 임베딩 층은 룩업 테이블이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S-D0d-X3jA7H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j4PHvj3jGqi",
        "outputId": "ce110440-e31a-4470-8738-02adba09bbfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'code': 2, 'to': 3, 'know': 4, 'how': 5, 'need': 6, 'you': 7, '<unk>': 0, '<pad>': 1}\n"
          ]
        }
      ],
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
        "word_set = set(train_data.split())\n",
        "\n",
        "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
        "vocab = {word: i+2 for i, word in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MoxV6Xo0jH3p"
      },
      "outputs": [],
      "source": [
        "# 단어 집합의 크기만큼의 행을 가지는 테이블 생성.\n",
        "embedding_table = torch.FloatTensor(\n",
        "    [\n",
        "        [0.0, 0.0, 0.0],\n",
        "        [0.0, 0.0, 0.0],\n",
        "        [0.2, 0.9, 0.3],\n",
        "        [0.1, 0.5, 0.7],\n",
        "        [0.2, 0.1, 0.8],\n",
        "        [0.4, 0.1, 0.1],\n",
        "        [0.1, 0.8, 0.9],\n",
        "        [0.6, 0.1, 0.1],\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKL9-0X2jJI5",
        "outputId": "f791d880-4943-4c38-9094-3670b23e164d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6000, 0.1000, 0.1000],\n",
            "        [0.1000, 0.8000, 0.9000],\n",
            "        [0.1000, 0.5000, 0.7000],\n",
            "        [0.0000, 0.0000, 0.0000]])\n"
          ]
        }
      ],
      "source": [
        "sample = 'you need to run'.split()\n",
        "idxes = []\n",
        "\n",
        "# 각 단어를 정수로 변환\n",
        "for word in sample:\n",
        "  try: # vocab 딕셔너리는 단어에 인덱스를 매핑한 딕셔너리다.\n",
        "    idxes.append(vocab[word])\n",
        "  # 단어 집합에 없는 단어일 경우 <unk>로 대체된다.\n",
        "  except KeyError:\n",
        "    idxes.append(vocab['<unk>'])\n",
        "idxes = torch.LongTensor(idxes)\n",
        "\n",
        "# 각 정수를 인덱스로 임베딩 테이블에서 값을 가져온다.\n",
        "lookup_result = embedding_table[idxes, :]\n",
        "print(lookup_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8zK8DapjbeX"
      },
      "source": [
        "## 2. 임베딩 층 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hnUprmtCjKLR"
      },
      "outputs": [],
      "source": [
        "train_data = 'you need to know how to code'\n",
        "\n",
        "# 중복을 제거한 단어들의 집합인 단어 집합 생성.\n",
        "word_set = set(train_data.split())\n",
        "\n",
        "# 단어 집합의 각 단어에 고유한 정수 맵핑.\n",
        "vocab = {tkn: i+2 for i, tkn in enumerate(word_set)}\n",
        "vocab['<unk>'] = 0\n",
        "vocab['<pad>'] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g4Jl0XfejMHB"
      },
      "outputs": [],
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n",
        "                               embedding_dim=3,\n",
        "                               padding_idx=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjVsgSJkjNIg",
        "outputId": "9eb59fdb-c710-4127-c227-d130d51302b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.7832, -0.9979, -0.1355],\n",
            "        [ 0.0000,  0.0000,  0.0000],\n",
            "        [-0.2762,  1.2631,  0.2748],\n",
            "        [-1.6141,  0.1397, -0.8243],\n",
            "        [ 0.2771, -1.1652, -0.1700],\n",
            "        [ 0.5433, -0.5194, -1.0798],\n",
            "        [ 0.8225, -1.0602, -0.4281],\n",
            "        [ 1.2721,  0.0168, -0.7378]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(embedding_layer.weight)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
