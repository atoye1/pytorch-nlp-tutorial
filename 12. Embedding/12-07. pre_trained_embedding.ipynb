{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 사전 훈련된 임베딩을 사용하지 않는 경우"
      ],
      "metadata": {
        "id": "-qRG5Y1mla_X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bimxw_OXjhjo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]"
      ],
      "metadata": {
        "id": "yxK3DWCpjmsp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences = [sent.split() for sent in sentences]\n",
        "print('단어 토큰화 된 결과 :', tokenized_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMQeKiipjn5I",
        "outputId": "131b9d3d-2dc5-4bf0-e956-e85fdfec99a5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화 된 결과 : [['nice', 'great', 'best', 'amazing'], ['stop', 'lies'], ['pitiful', 'nerd'], ['excellent', 'work'], ['supreme', 'quality'], ['bad'], ['highly', 'respectable']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = []\n",
        "for sent in tokenized_sentences:\n",
        "    for word in sent:\n",
        "      word_list.append(word)\n",
        "\n",
        "word_counts = Counter(word_list)\n",
        "print('총 단어수 :', len(word_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBk9Cfc9jpOA",
        "outputId": "dc657e4b-4c42-4ed0-aeda-435a27f0b715"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 단어수 : 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 등장 빈도순으로 정렬\n",
        "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fcKTXB-jqQ4",
        "outputId": "2807afa2-da57-4e91-eb87-43ae29068546"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nice', 'great', 'best', 'amazing', 'stop', 'lies', 'pitiful', 'nerd', 'excellent', 'work', 'supreme', 'quality', 'bad', 'highly', 'respectable']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = {}\n",
        "word_to_index['<PAD>'] = 0\n",
        "word_to_index['<UNK>'] = 1\n",
        "\n",
        "for index, word in enumerate(vocab) :\n",
        "  word_to_index[word] = index + 2\n",
        "\n",
        "vocab_size = len(word_to_index)\n",
        "print('패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기 :', vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Uqm_0icjrNg",
        "outputId": "3666a3b7-6ac8-452d-c3dc-f3777cd073ac"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 토큰, UNK 토큰을 고려한 단어 집합의 크기 : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m54u1LEvjsOY",
        "outputId": "a3dbcaf4-4031-4aec-95a1-3bdec9e0d84f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, '<UNK>': 1, 'nice': 2, 'great': 3, 'best': 4, 'amazing': 5, 'stop': 6, 'lies': 7, 'pitiful': 8, 'nerd': 9, 'excellent': 10, 'work': 11, 'supreme': 12, 'quality': 13, 'bad': 14, 'highly': 15, 'respectable': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
        "  encoded_X_data = []\n",
        "  for sent in tokenized_X_data:\n",
        "    index_sequences = []\n",
        "    for word in sent:\n",
        "      try:\n",
        "          index_sequences.append(word_to_index[word])\n",
        "      except KeyError:\n",
        "          index_sequences.append(word_to_index['<UNK>'])\n",
        "    encoded_X_data.append(index_sequences)\n",
        "  return encoded_X_data\n",
        "\n",
        "X_encoded = texts_to_sequences(tokenized_sentences, word_to_index)\n",
        "print(X_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4FQ4ajbjtSI",
        "outputId": "0bc9ccf4-09e2-4deb-f259-054624e059c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3, 4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14], [15, 16]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max(len(l) for l in X_encoded)\n",
        "print('최대 길이 :',max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj3qBy3Wjuh4",
        "outputId": "8f33e7ba-d5e0-40ec-dc23-a44dd65f2942"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최대 길이 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sentences, max_len):\n",
        "  features = np.zeros((len(sentences), max_len), dtype=int)\n",
        "  for index, sentence in enumerate(sentences):\n",
        "    if len(sentence) != 0:\n",
        "      features[index, :len(sentence)] = np.array(sentence)[:max_len]\n",
        "  return features\n",
        "\n",
        "X_train = pad_sequences(X_encoded, max_len=max_len)\n",
        "y_train = np.array(y_train)\n",
        "print('패딩 결과 :')\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KB85pXwjvxY",
        "outputId": "ab8f6ab0-9f8e-4a57-d894-856bd8e86fd6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "패딩 결과 :\n",
            "[[ 2  3  4  5]\n",
            " [ 6  7  0  0]\n",
            " [ 8  9  0  0]\n",
            " [10 11  0  0]\n",
            " [12 13  0  0]\n",
            " [14  0  0  0]\n",
            " [15 16  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "VY5TN1ihjwqQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(embedding_dim * max_len, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # embedded.shape == (배치 크기, 문장의 길이, 임베딩 벡터의 차원)\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # flattend.shape == (배치 크기, 문장의 길이 × 임베딩 벡터의 차원)\n",
        "        flattened = self.flatten(embedded)\n",
        "\n",
        "        # output.shape == (배치 크기, 1)\n",
        "        output = self.fc(flattened)\n",
        "        return self.sigmoid(output)"
      ],
      "metadata": {
        "id": "YRJBVJnTjyMI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "embedding_dim = 100\n",
        "simple_model = SimpleModel(vocab_size, embedding_dim).to(device)"
      ],
      "metadata": {
        "id": "i5kzuuFAjzmg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(simple_model.parameters())"
      ],
      "metadata": {
        "id": "bVOBQDvVj1Ig"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2)"
      ],
      "metadata": {
        "id": "LQHuL9j7j19o"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fVHHtywj2sa",
        "outputId": "269af5ac-6a99-4929-d9c3-1d9bcf4dcd53"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    for inputs, targets in train_dataloader:\n",
        "        # inputs.shape == (배치 크기, 문장 길이)\n",
        "        # targets.shape == (배치 크기)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # outputs.shape == (배치 크기)\n",
        "        outputs = simple_model(inputs).view(-1)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVeJm3BBj5Uo",
        "outputId": "1b680dcb-59c8-48db-c926-83c926c39434"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.875236988067627\n",
            "Epoch 2, Loss: 0.6451760530471802\n",
            "Epoch 3, Loss: 0.4630502164363861\n",
            "Epoch 4, Loss: 0.34133291244506836\n",
            "Epoch 5, Loss: 0.26545217633247375\n",
            "Epoch 6, Loss: 0.2187986522912979\n",
            "Epoch 7, Loss: 0.18912285566329956\n",
            "Epoch 8, Loss: 0.16851575672626495\n",
            "Epoch 9, Loss: 0.1521947830915451\n",
            "Epoch 10, Loss: 0.1375783085823059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 사전 훈련된 임베딩을 사용하는 경우"
      ],
      "metadata": {
        "id": "G9GtkHwQlgrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAhpRS-Ij6UQ",
        "outputId": "ffc5c68c-bd26-4117-b784-dd49d8bf6a98"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.15.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.7.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j\n",
            "From (redirected): https://drive.google.com/uc?id=1Av37IVBQAAntSe1X3MOAl5gvowQzd2_j&confirm=t&uuid=470bb0f3-a860-4698-b942-a5d0be627a72\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "100% 1.65G/1.65G [00:15<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글의 사전 훈련된 Word2vec 모델을 로드합니다.\n",
        "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "metadata": {
        "id": "oYDvMZUHlZWh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "print('임베딩 행렬의 크기 :', embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ihZSM0liWx",
        "outputId": "c6f7e507-ad61-4951-fa58-1d615467fa45"
      },
      "execution_count": 23,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "임베딩 행렬의 크기 : (17, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector(word):\n",
        "    if word in word2vec_model:\n",
        "        return word2vec_model[word]\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "zjhjImCIljeq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <PAD>를 위한 0번과 <UNK>를 위한 1번은 실제 단어가 아니므로 맵핑에서 제외\n",
        "for word, i in word_to_index.items():\n",
        "    if i > 2:\n",
        "      temp = get_vector(word)\n",
        "      if temp is not None:\n",
        "          embedding_matrix[i] = temp"
      ],
      "metadata": {
        "id": "p60bQwOvlkW6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <PAD>나 <UNK>의 경우는 사전 훈련된 임베딩이 들어가지 않아서 0벡터임\n",
        "print(embedding_matrix[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Yj_Y1FllRA",
        "outputId": "bb833ef2-9be3-4a4d-f2c3-cc9313975d7d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index['great']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lppdk8elmNB",
        "outputId": "1c57ed17-207a-4fe7-bb7d-e7f861b62ebf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec_model에서 'great'의 임베딩 벡터\n",
        "# embedding_matrix[3]이 일치하는지 체크\n",
        "np.all(word2vec_model['great'] == embedding_matrix[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDx60D3bloSg",
        "outputId": "4e7d1b53-f4ad-44c4-d673-2e0e48342d02"
      },
      "execution_count": 28,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PretrainedEmbeddingModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(PretrainedEmbeddingModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = True\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(embedding_dim * max_len, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        flattened = self.flatten(embedded)\n",
        "        output = self.fc(flattened)\n",
        "        return self.sigmoid(output)"
      ],
      "metadata": {
        "id": "exsxaDyllpOo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretraiend_embedding_model = PretrainedEmbeddingModel(vocab_size, 300).to(device)"
      ],
      "metadata": {
        "id": "inamSET_lqqI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = Adam(pretraiend_embedding_model.parameters())"
      ],
      "metadata": {
        "id": "lQlIdg0tlr4B"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2)"
      ],
      "metadata": {
        "id": "ceu_hZV2ls3o"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDsfFBgKlty4",
        "outputId": "9205e3f6-06ce-40f4-a6eb-3831b763b6f7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    for inputs, targets in train_dataloader:\n",
        "        # inputs.shape == (배치 크기, 문장 길이)\n",
        "        # targets.shape == (배치 크기)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # outputs.shape == (배치 크기)\n",
        "        outputs = pretraiend_embedding_model(inputs).view(-1)\n",
        "\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCOL7YUelut4",
        "outputId": "226dfc3d-bdea-4216-f684-34efa7b64a9e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.6507558822631836\n",
            "Epoch 2, Loss: 0.5911518931388855\n",
            "Epoch 3, Loss: 0.5319837927818298\n",
            "Epoch 4, Loss: 0.476415753364563\n",
            "Epoch 5, Loss: 0.42526787519454956\n",
            "Epoch 6, Loss: 0.37870797514915466\n",
            "Epoch 7, Loss: 0.3366509675979614\n",
            "Epoch 8, Loss: 0.29889577627182007\n",
            "Epoch 9, Loss: 0.2651826739311218\n",
            "Epoch 10, Loss: 0.23521865904331207\n"
          ]
        }
      ]
    }
  ]
}