{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Repeat', 'medicine', 'memory', 'best', 'the', 'for', 'is']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Repeat is the best medicine for memory\".split()\n",
    "sentence.sort()\n",
    "vocab = list(set(sentence))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Repeat': 1,\n",
       " 'medicine': 2,\n",
       " 'memory': 3,\n",
       " 'best': 4,\n",
       " 'the': 5,\n",
       " 'for': 6,\n",
       " 'is': 7,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {word: i + 1 for i, word in enumerate(vocab)}\n",
    "word2index['<unk>'] = 0\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Repeat',\n",
       " 2: 'medicine',\n",
       " 3: 'memory',\n",
       " 4: 'best',\n",
       " 5: 'the',\n",
       " 6: 'for',\n",
       " 7: 'is',\n",
       " 0: '<unk>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = {value : key for key, value in word2index.items()}\n",
    "index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(sentence, word2index):\n",
    "    encoded = [word2index[token] for token in sentence]\n",
    "    input_seq, label_seq = encoded[:-1], encoded[1:]\n",
    "    input_seq = torch.LongTensor(input_seq).unsqueeze(0)\n",
    "    label_seq = torch.LongTensor(label_seq).unsqueeze(0)\n",
    "    return input_seq, label_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 6, 7, 2, 3]]), tensor([[4, 6, 7, 2, 3, 5]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_data(sentence, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 6, 7, 2, 3]])\n",
      "tensor([[4, 6, 7, 2, 3, 5]])\n"
     ]
    }
   ],
   "source": [
    "X, Y = build_data(sentence, word2index)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_size, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size, embedding_dim=input_size)\n",
    "        self.rnn_layer = nn.RNN(input_size, hidden_size, batch_first=batch_first)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        output= self.embedding_layer(x)\n",
    "        output, hidden = self.rnn_layer(output)\n",
    "        output = self.linear(output)\n",
    "        return output.view(-1, output.size(2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
