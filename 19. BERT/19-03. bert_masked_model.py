# -*- coding: utf-8 -*-
"""19-03. bert_masked_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16ATIjT5ipJ6yoMAI94Fk0btWUW5OKc_w

## 1. 마스크드 언어 모델과 토크나이저
"""

pip install transformers

from transformers import BertForMaskedLM
from transformers import AutoTokenizer

model = BertForMaskedLM.from_pretrained('bert-large-uncased')
tokenizer = AutoTokenizer.from_pretrained("bert-large-uncased")

"""## 2. BERT의 입력"""

inputs = tokenizer('Soccer is a really fun [MASK].')

print(inputs['input_ids'])

print(inputs['token_type_ids'])

print(inputs['attention_mask'])

"""## 3. [MASK] 토큰 예측하기"""

from transformers import FillMaskPipeline
pip = FillMaskPipeline(model=model, tokenizer=tokenizer)

pip('Soccer is a really fun [MASK].')

pip('The Avengers is a really fun [MASK].')

pip('I went to [MASK] this morning.')

"""## 4. 마스크드 언어 모델과 토크나이저"""

from transformers import BertForMaskedLM
from transformers import AutoTokenizer

model = BertForMaskedLM.from_pretrained('klue/bert-base')
tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")

"""## 5. BERT의 입력"""

inputs = tokenizer('축구는 정말 재미있는 [MASK]다.')

print(inputs['input_ids'])

print(inputs['token_type_ids'])

print(inputs['attention_mask'])

"""## 6. [MASK] 토큰 예측하기"""

from transformers import FillMaskPipeline
pip = FillMaskPipeline(model=model, tokenizer=tokenizer)

pip('축구는 정말 재미있는 [MASK]다.')

pip('어벤져스는 정말 재미있는 [MASK]다.')

pip('나는 오늘 아침에 [MASK]에 출근을 했다.')