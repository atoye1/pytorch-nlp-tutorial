{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qx1jSvcNIej",
        "outputId": "1de44057-0aaf-459b-ca51-ecfc681e5e3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "bAg-haUfmwWK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', pad_token='<pad>')\n",
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22gK1Ea3mxUq",
        "outputId": "869fa7fd-9429-4847-e1b6-59b86715074d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.bos_token_id)\n",
        "print(tokenizer.eos_token_id)\n",
        "print(tokenizer.pad_token_id)\n",
        "print('-' * 10)\n",
        "print(tokenizer.decode(1))\n",
        "print(tokenizer.decode(2))\n",
        "print(tokenizer.decode(3))\n",
        "print(tokenizer.decode(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G6OFuj5n5dz",
        "outputId": "05c44809-dd1a-4a19-d8a4-c64bc87e3f0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "3\n",
            "----------\n",
            "</s>\n",
            "<usr>\n",
            "<pad>\n",
            "<sys>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tqdm\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "dckISrGSmyQ1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
        "train_data = pd.read_csv('ChatBotData.csv')"
      ],
      "metadata": {
        "id": "7KMXXlMYm8nb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgBLUI34cHqg",
        "outputId": "4cfcee88-a3d1-4d98-cfff-2ca23c6c0cac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11823"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32"
      ],
      "metadata": {
        "id": "RQf3VZM8dsuQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, train_data, tokenizer):\n",
        "        self.train_data = train_data\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        question = self.train_data.Q.iloc[idx]\n",
        "        answer = self.train_data.A.iloc[idx]\n",
        "        bos_token = self.tokenizer.bos_token_id\n",
        "        eos_token = self.tokenizer.eos_token_id\n",
        "        sent = self.tokenizer.encode('<usr>' + question + '<sys>' + answer, add_special_tokens=False)\n",
        "        return torch.tensor([bos_token] + sent + [eos_token], dtype=torch.long)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "\n",
        "batch_size = 32\n",
        "chat_dataset = ChatDataset(train_data, tokenizer)\n",
        "data_loader = DataLoader(chat_dataset, batch_size=batch_size, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "KjJY33uHZadR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5, eps=1e-08)\n",
        "\n",
        "steps = len(train_data) // batch_size + 1\n",
        "print(steps)\n",
        "\n",
        "EPOCHS = 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr_rVEayZ6zQ",
        "outputId": "ad338703-0357-432d-afb3-3ab825eb8c1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in tqdm.tqdm(data_loader, total=steps):\n",
        "        batch = batch.to(device)\n",
        "        labels = batch.clone()\n",
        "        optimizer.zero_grad()\n",
        "        result = model(input_ids=batch, labels=labels)\n",
        "        loss = result.loss\n",
        "        batch_loss = loss.mean()\n",
        "        \n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += batch_loss.item() / steps\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, epoch_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb6eeDssZ8uA",
        "outputId": "6cb530f9-12ea-460a-ef85-30dc2353e05f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 370/370 [01:41<00:00,  3.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 2.12702096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 370/370 [01:46<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    2] cost = 1.69815452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 370/370 [01:46<00:00,  3.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    3] cost = 1.37507791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = '오늘도 좋은 하루!'"
      ],
      "metadata": {
        "id": "QyxDdtOapWat"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = '<usr>' + text + '<sys>'"
      ],
      "metadata": {
        "id": "VCrTFarcqUD2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [tokenizer.bos_token_id] + tokenizer.encode(sent)\n",
        "input_ids = torch.tensor([input_ids], dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "CMAEUZyiqXQ9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(input_ids, max_length=50, early_stopping=True, eos_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "D5ptIm69qZ9A"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sentence = tokenizer.decode(output[0].tolist())"
      ],
      "metadata": {
        "id": "irT0H8nBqc3v"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_sentence.split('<sys> ')[1].replace('</s>', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZDXWzgzWqh53",
        "outputId": "6a341f39-1c13-4271-badc-a8166bc760fc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'좋은 하루네요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(input_ids, max_length=50, do_sample=True, top_k=10)\n",
        "tokenizer.decode(output[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "k2qenmvIqoaE",
        "outputId": "7c526a03-794a-498e-fa1e-2317030b6c73"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'</s><usr> 오늘도 좋은 하루!<sys> 좋은 하루!</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def return_answer_by_chatbot(user_text):\n",
        "    sent = '<usr>' + user_text + '<sys>'\n",
        "    input_ids = [tokenizer.bos_token_id] + tokenizer.encode(sent, add_special_tokens=False)\n",
        "    input_ids = torch.tensor([input_ids], dtype=torch.long).to(device)\n",
        "    output = model.generate(input_ids, max_length=50, do_sample=True, top_k=2)\n",
        "    sentence = tokenizer.decode(output[0].tolist())\n",
        "    chatbot_response = sentence.split('<sys> ')[1].replace('</s>', '')\n",
        "    return chatbot_response"
      ],
      "metadata": {
        "id": "cFTDp_c8a7Em"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('안녕! 반가워~')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kdK6SxmMrym3",
        "outputId": "1c3023ec-9795-42af-e7c3-2af6a2396519"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'반가워요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('너는 누구야?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BNgtzJUwsHbB",
        "outputId": "0294ff49-7bf6-4e8c-f251-6a0348cdd220"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'저는 짝사랑이에요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('사랑해')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "m6n2S6Lcr2vm",
        "outputId": "240026fd-7a81-4c5a-8aa9-f28f296aa501"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'사랑해 보세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('나랑 영화보자')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-i0WsJDZr6AZ",
        "outputId": "4056368f-9596-46d3-a855-5b6d6bb51e4f"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'영화 한 편 보세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('너무 심심한데 나랑 놀자')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tVvEDRaZsTjf",
        "outputId": "6c8d9974-8422-48c4-b814-42fd9d677067"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'짝사랑은 영원할 거예요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('영화 해리포터 재밌어?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPRgzN3Ihk60",
        "outputId": "c2e7f58c-a8eb-43a3-f70a-c2d77f5cad60"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'영화나 드라마는 다 비슷하죠.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('너 딥 러닝 잘해?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_4nbS1inhmW2",
        "outputId": "bbf16307-232b-4eef-ff47-87a2550a3207"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'잘할 수 있어요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('너 취했어?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mMTBnJQhho-X",
        "outputId": "08cc8d11-0f98-4eb6-d1fa-0170bd4b8f22"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'취했어요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "return_answer_by_chatbot('커피 한 잔 할까?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UCB6xzE4pYnR",
        "outputId": "12d10b94-45f4-4ee2-82ab-3b3e93b1f287"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'커피가 좋죠.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ]
}