# -*- coding: utf-8 -*-
"""21-02. gpt_sentence_genernation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EzMTzpiWU80wZh7Sdb649Z5n7OPI0jlg
"""

!pip install transformers

"""# 1. KoGPT2로 문장 생성하기

"""

from transformers import AutoTokenizer
from transformers import GPT2LMHeadModel

tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')

model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')

sent = '근육이 커지기 위해서는'

input_ids = tokenizer.encode(sent, return_tensors='pt')
print(input_ids)

tokenizer.decode([33245])

tokenizer.decode([10114])

tokenizer.decode([12748])

tokenizer.decode([11357])

output = model.generate(input_ids,
                        max_length=128,
                        repetition_penalty=2.0,
                        use_cache=True)
output_ids = output.numpy().tolist()[0]
print(output_ids)

tokenizer.decode(output_ids)

"""# 2. Numpy로 Top 5 뽑기"""

import numpy as np
import torch

output = model(input_ids)

output.logits

output.logits.shape

logits = output.logits[0, -1]

logits.shape

top5 = torch.topk(logits, k=5)
tokens = [tokenizer.decode(token_id) for token_id in top5.indices.tolist()]

print(tokens)

"""# 3. Numpy Top 5로 문장 생성하기"""

import random

sent = '근육이 커지기 위해서는'
input_ids = tokenizer.encode(sent, return_tensors='pt')

print(input_ids)

import random
import time

random.seed(time.time())

while len(input_ids[0]) < 50:
    with torch.no_grad():
        output = model(input_ids)
    logits = output.logits[0, -1]
    top5 = torch.topk(logits, k=30)
    token_id = random.choice(top5.indices.tolist())
    input_ids = torch.cat([input_ids, torch.tensor([[token_id]])], dim=1)

print(input_ids)

print(len(input_ids[0]))

tokenizer.decode(input_ids[0])